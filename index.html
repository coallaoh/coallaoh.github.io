<!DOCTYPE HTML>
<html lang="en">
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-JKQK3E33B3"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-JKQK3E33B3');
  </script>

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Alexander Rubinstein</title>

  <meta name="author" content="Alexander Rubinstein">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="pictures/personal_round.png">
  <script src="data/publications.js"></script>
  <script src="data/authors.js"></script>
  <script src="data/communities.js"></script>
  <script src="js/publications.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <script src="js/visualizations.js"></script>

</head>

<body>
  <!-- Dark Mode Toggle -->
  <div class="theme-switch-wrapper">
    <span class="darkmode-label">Light</span>
    <label class="theme-switch" for="checkbox">
      <input type="checkbox" id="checkbox" />
      <div class="slider"></div>
    </label>
    <span class="darkmode-label">Dark</span>
  </div>

  <div class="container">
    <div class="row" style="margin-top: 10px;">
      <div class="col-sm-8 name-column" style="min-width: 266px;">
        <p style="text-align:center">
          <name>Alexander Rubinstein</name>
        </p>
      </div>
      <div class="col-sm-8 name-column text-right" style="min-width: 266px;">
        <p style="text-align:center">
          <a href="https://scalabletrustworthyai.github.io/"><img src="pictures/stai_logo.png" alt="stai_logo" class="institute-logo"></a>
            &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
          <a href="https://tue.ai/"><img src="pictures/logo_tueai.svg" alt="tueai_logo" class="institute-logo"></a>
            &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
          <a href="https://uni-tuebingen.de/"><img src="pictures/logo_uni_tue.svg" alt="logo_uni_tue" class="institute-logo"></a>
            <!-- &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
          <a href="https://parameterlab.de/"><img src="pictures/logo_parameterlab.png" alt="logo_uni_tue" class="institute-logo"></a> -->
        </p>
      </div>
    </div>
    <div class="row common-rows">

      <div class="col-xs-12 col-sm-8 personal-column">
        <p>
          <!-- I am a professor at the <a href="https://tuebingen.ai/">University of Tübingen</a> leading the group on <a href="https://scalabletrustworthyai.github.io/">Scalable Trustworthy AI (STAI)</a>.
          In addition to my main job, I advise <a href="https://www.parameterlab.de/">Parameter Lab</a>.
          I am generally interested in training reliable models (<emph>e.g.</emph> explainable, robust, and probabilistic models) and obtaining the necessary human supervision and guidance in a cost-effective way.
           -->
           I am a PhD student at the <a href="https://tuebingen.ai/">University of Tübingen</a> and the <a href="https://imprs.is.mpg.de/">International Max Planck Research School for Intelligent Systems (IMPRS-IS)</a> working in the group on <a href="https://scalabletrustworthyai.github.io/">Scalable Trustworthy AI (STAI)</a>.
           My research focuses on developing reliable machine learning models that are explainable and robust.
        </p>
        <!-- <p>
          I have been a research scientist at <a href="https://github.com/naver-ai">NAVER AI Lab</a> for 3.5 years.
          I received my PhD in computer vision and machine learning at <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning">Max-Planck Institute for Informatics</a> in 2018,
          under the supervision of <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a> and <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>,
          with a focus on the privacy and security implications of CV and ML (<a href="https://publikationen.sulb.uni-saarland.de/handle/20.500.11880/27146">Thesis</a>).
          I received the Master of Mathematics with <a href="https://en.wikipedia.org/wiki/Part_III_of_the_Mathematical_Tripos">Distinction</a> in 2014 and
          Bachelor of Arts in Mathematics as a <a href="https://en.wikipedia.org/wiki/Wrangler_(University_of_Cambridge)">Wrangler</a> in 2013,
          both at University of Cambridge.
        </p> -->
        <p>
          I am doing my PhD in machine learning under the supervision of <a href="https://coallaoh.github.io/">Seong Joon Oh</a>,
          with a focus on the modularity of intelligent systems and data representations.
          I received the Master of Science in Applied Mathematics and Physics with honours in 2021 and
          Bachelor of Science in Applied Mathematics and Physics with honours in 2019,
          both at the <a href="https://old.mipt.ru/english/">Moscow Institute of Physics and Technology</a>.
        </p>
        <!-- <p>
          I started compiling the <a href="https://github.com/coallaoh/Principles">principles for life and research &#127822;</a>.
        </p> -->

        <p style="text-align:center">
          <a href="https://researchtrend.ai/authors/alexander-rubinstein-1">ResearchTrend.AI</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=upi0cDcAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
          <a href="https://www.linkedin.com/in/alexander-rubinstein-043564116/">LinkedIn</a> &nbsp/&nbsp
          <a href="https://x.com/a_rubique">Twitter</a> &nbsp/&nbsp
          <a href="https://github.com/arubique">Github</a>
        </p>

      </div>
      <div class="col-xs-12 col-sm-4 personal-column">
        <img alt="profile photo" src="pictures/personal_round.png" class="personal-photo">
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row section-heading-rows">
      <h3>Updates</h3>
    </div>
    <div class="row">
      <p>
        <ul>
          <!-- <li>1 May 2025. 1 paper on <a href="#arnas2025icml">compositional generalisation</a> is accepted at ICML'25.</li> -->
          <li>01 June 2025. I have used the template from <a href="https://coallaoh.github.io/">Joon</a> powered by <a href="https://www.researchtrend.ai/">ResearchTrend.AI</a> for my personal website.</li>
          <!-- <li>23 January 2025. 1 paper on <a href="#haritz2025mia">making MIA work</a> is accepted at NAACL'25</li>
          <li>23 January 2025. We have 3 papers to be presented at ICLR'25: <a href="#ankit2025star">Star Domain Hypothesis</a>, <a href="#arnas2025iclr">Intermediate-Layer Classifiers</a>, <a href="#jaehyun2025iclr">Finetuning Segmenter</a>.</li>
          <li>5 October 2024. I'm teaching the <a href="https://scalabletrustworthyai.github.io/courses/tml_winter_2425/">Trustworthy ML course</a> @ University of Tübingen.</li> -->
      </p>
    </div>
  </div>


  <!-- <div class="container">
    <div class="row section-heading-rows">
      <h3>Research</h3>
    </div>
    <div class="row">
      <p>
        I have tried to push certain fronts in ML research to make models truly useful and deployable in real life. They can be grouped into a few keywords.
        <br><br>
        <span style="background-color:#ff9aa2">Robustness</span>.
        Changes in the input distribution shall not disrupt the model's predictive power. Ideally, a model should be robust against the shifts in input domain (<em>e.g.</em> natural and adversarial perturbations) and confounders (<em>e.g.</em> fairness).
        <br><br>
        <span style="background-color:#ffdac1">Uncertainty</span>.
        A model should know when it is going to get it wrong. This allows the users and downstream systems to make sensible and safe decisions based on the estimated confidence levels.
        <br><br>
        <span style="background-color:#ffffce">Human Annotation</span>.
        An integral part of training a high-performance model is the human supervision. I have sought cost-effective ways to extract useful supervisory signals from humans.
        <br><br>
        <span style="background-color:#b5ead7">Privacy & Security</span>.
        There are different privacy and security angles with which ML can be analyzed. One may question the "stealability" of a black-box model as an IP; one may also question the privacy guarantees for user data in the federated learning setup.
        Still others may wonder whether certain level privacy is achievable at all on internet, with the increasing volume of user data online and more widespread use of machine learning algorithms to process such data.
        <br><br>
        <span style="background-color:#c7ceea">Explainability</span>.
        Humans do not use systems that are not trustworthy. Humans thus find it hard to deal with systems that do not explain the rationale. Explanations are an integral part of trustworthiness. A model must provide a faithful reasoning for its decisions, ideally paving way to practical action items to improve the model.
        <br><br>
        <span style="background-color:#e2c7e5">Evaluation</span>.
        Correct evaluation is undoubtably important in research and industrial applications, yet it is surprisingly difficult. I have cleaned up benchmarks and evaluation protocols in a few domains.
        <br><br>
        <span style="background-color:#C9D3D8">Large-Scale ML</span>.
        Some of the methodologies I have been involved in are designed for large-scale ML. They typically require minimal changes to the original ML system but bring consistent gains across the board.
        <br><br>
        See <a href="https://docs.google.com/presentation/d/1BVyjRE-jq3cuVl9NM29WeFi6eUBTtPi6KzKRQufJr4g/edit?usp=sharing">slides</a> and <a href="https://www.youtube.com/watch?v=oiFS2N1ocTA">video</a> (3 Aug 2022) for an overview of the past researches and future research ideas for the scalable trustworthy AI.
      </p>
    </div>
  </div> -->

  <div class="container">
    <div class="row section-heading-rows">
      <h3>Research Communities</h3>
    </div>
    <div class="row">
      <div class="col-12">
        <canvas id="topicTrendsChart" style="width:100%; height:400px;"></canvas>
      </div>
    </div>
    <div class="row mt-3 mb-4">
      <div class="col-12">
        <div class="d-flex justify-content-center mb-2">
          <button id="selectAllCommunities" class="community-control-btn mr-2">Select All</button>
          <button id="clearAllCommunities" class="community-control-btn">Clear All</button>
        </div>
        <div id="communityFilters" class="community-filters-container">
          <!-- Community filter toggles will be added here dynamically -->
        </div>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row section-heading-rows">
      <h3 id="publications-heading">Publications</h3>
    </div>

    <div id="publications-container">
      <!-- Publications will be loaded here via JavaScript -->
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col">
        <p style="text-align:center;font-size:small;">
          Template based on <a href="https://coallaoh.github.io/">Seong Joon Oh's website</a> (modified from <a href="https://jonbarron.info/">Jon Barron's website</a>).
        </p>
      </div>
    </div>
  </div>

  <style>
    .community-filters-container {
      max-width: 900px;
      margin: 0 auto;
      overflow-y: visible;
    }
    .community-control-btn {
      background-color: #555555;
      color: white;
      border: none;
      border-radius: 4px;
      padding: 5px 15px;
      font-size: 14px;
      cursor: pointer;
      margin: 0 5px;
    }
    .community-control-btn:hover {
      background-color: #333333;
    }
    .community-toggle-table td {
      line-height: 1.2;
    }

    /* Hide logos in dark mode */
    [data-theme="dark"] .institute-logo {
      display: none;
    }
  </style>

  <script>
    // Dark mode functionality
    const toggleSwitch = document.querySelector('#checkbox');
    const currentTheme = localStorage.getItem('theme');

    // Function to set theme
    function setTheme(theme) {
      document.documentElement.setAttribute('data-theme', theme);
      localStorage.setItem('theme', theme);

      if (theme === 'dark') {
        toggleSwitch.checked = true;
      } else {
        toggleSwitch.checked = false;
      }

      // Update charts if they exist
      if (typeof updateChartTheme === 'function') {
        try {
          updateChartTheme();
        } catch (error) {
          console.log('Chart update failed:', error);
        }
      }
    }

    // Check for saved user preference, if any
    if (currentTheme) {
      setTheme(currentTheme);
    } else {
      // If no preference stored, check system preference
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
        setTheme('dark');
      } else {
        setTheme('light');
      }
    }

    // Listen for toggle switch change
    toggleSwitch.addEventListener('change', function(e) {
      if (e.target.checked) {
        setTheme('dark');
      } else {
        setTheme('light');
      }
    });

    // Listen for system preference changes
    window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', e => {
      const newTheme = e.matches ? 'dark' : 'light';
      // Only apply if user hasn't manually set a preference
      if (!localStorage.getItem('theme')) {
        setTheme(newTheme);
      }
    });
  </script>
</body>

</html>
